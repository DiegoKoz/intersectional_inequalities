{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outdated\n",
    "\n",
    "I won't use the weighted by citations approach anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.sklearn\n",
    "import re\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import unicodedata2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#from libs.lda_wrapper import LDA_wrapper\n",
    "from libs.LastNamesInference import LastNamesInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full = pd.read_csv('/data/WOS/US/text_clean.txt')\n",
    "df_socsci = pd.read_csv('/data/datasets/WOS/US/text_clean_socsci.txt')\n",
    "us_papers = pd.read_csv('/data/datasets/WOS/US/US_papers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_papers['cit_rel_all_IAC'] = us_papers['cit_rel_all_IAC'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(x, file_name):\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def restore(file_name):\n",
    "    with open(file_name, 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_race(us_papers,df_socsci, authors='first'):\n",
    "    socsci_papers = us_papers.loc[(us_papers.id_art.isin(df_socsci.id_art)),]\n",
    "    first_authors = socsci_papers[socsci_papers.ordre==1].copy().reset_index(drop=True)\n",
    "    #first_authors = first_authors[['id_art','Prenom', 'nom']]\n",
    "    lni = LastNamesInference(names = first_authors.nom)\n",
    "    tqdm.pandas(desc=\"inferring race from lastnames\")\n",
    "    lastname_race_dist = first_authors.progress_apply(lambda x: lni.get_name_dist(lastname=x.nom), axis=1)\n",
    "    first_authors[lni.prob_order] = pd.DataFrame(lastname_race_dist.to_list())\n",
    "    #first_authors = first_authors[['id_art','white', 'hispanic', 'black', 'asian']]\n",
    "    df_socsci_race = df_socsci.merge(first_authors, on ='id_art')\n",
    "\n",
    "    return df_socsci_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(df,dataset= 'full',n_components=100):\n",
    "    if not os.path.exists('../results/lda_model_{}_k{}.p'.format(dataset,n_components)):\n",
    "        warnings.warn('we do not have that model')\n",
    "    else:\n",
    "        lda_model = restore( '../results/lda_model_{}_k{}.p'.format(dataset,n_components))\n",
    "        vectorizer = restore( '../results/vectorizer_{}.p'.format(dataset))\n",
    "    return lda_model,vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df,lda_model,vectorizer):\n",
    "    texts = df.text_clean.values\n",
    "    data_vectorized = vectorizer.transform(texts)\n",
    "    doc_dist = lda_model.transform(data_vectorized)\n",
    "    return data_vectorized, doc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_race_dist(df_race):\n",
    "    df_race = df_race.copy()\n",
    "    df_race.loc[:,['white', 'hispanic', 'black', 'asian']] = df_race[['white', 'hispanic', 'black', 'asian']].multiply(df_race[\"cit_rel_all_IAC\"], axis=\"index\")\n",
    "    return df_race\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_lda_topics(df_race,doc_dist):\n",
    "        \n",
    "    race_dist = df_race.filter(regex=('white|hispanic|black|asian'))\n",
    "    topics_by_group = race_dist.T @ doc_dist \n",
    "    \n",
    "    joint_prob = topics_by_group/topics_by_group.to_numpy().sum()\n",
    "    marginal_by_topic = joint_prob.div(joint_prob.sum(axis=0), axis=1)\n",
    "    marginal_by_group = joint_prob.div(joint_prob.sum(axis=1), axis=0)\n",
    "#    dist_diff_topic = marginal_by_topic.subtract(joint_prob.sum(axis=1), axis=0)  # with the substraction, this gives \"how many percentual points (more/less) than \n",
    "                                                                                    # expected they talk about this topic\n",
    "    dist_diff_topic = marginal_by_topic.div(joint_prob.sum(axis=1), axis=0) -1   # with the ratio, this gives \"how much % (more/less) than expected\n",
    "                                                                                    # they talk about this topic\n",
    "    joint_prob = joint_prob.T.rename_axis('topic').reset_index()\n",
    "    marginal_by_topic = marginal_by_topic.T.rename_axis('topic').reset_index()\n",
    "    marginal_by_group = marginal_by_group.T.rename_axis('topic').reset_index()\n",
    "    dist_diff_topic = dist_diff_topic.T.rename_axis('topic').reset_index()\n",
    "    \n",
    "    # I start the topics in 1, so they are equal to the LDAVIZ!!!!\n",
    "    joint_prob.topic += 1\n",
    "    marginal_by_topic.topic += 1\n",
    "    marginal_by_group.topic += 1\n",
    "    dist_diff_topic.topic += 1    \n",
    "    \n",
    "    return joint_prob, marginal_by_topic, marginal_by_group, dist_diff_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_by_gender(df_race, doc_dist, weighted = True):\n",
    "    \n",
    "    \n",
    "    if weighted is True:\n",
    "        df_race = weighted_race_dist(df_race)\n",
    "    #race_dist = race_dist.merge(metadata_papers, how='left', left_index=True, right_on='id_art')\n",
    "    #race_dist = first_or_so_authors(race_dist)\n",
    "\n",
    "    df_race['gender'] = df_race.gender.str.upper()\n",
    "\n",
    "    boolean_mask_M = df_race.gender == 'M'\n",
    "    boolean_mask_F = df_race.gender == 'F'\n",
    "    \n",
    "    race_dist_M = df_race.loc[boolean_mask_M,['white','hispanic','black','asian']]\n",
    "    race_dist_F = df_race.loc[boolean_mask_F,['white','hispanic','black','asian']]\n",
    "\n",
    "    race_dist_M.columns = race_dist_M.columns + '_M'\n",
    "    race_dist_F.columns = race_dist_F.columns + '_F'\n",
    "\n",
    "    race_dist_MF = pd.concat([race_dist_M,race_dist_F]).fillna(0)\n",
    "    doc_dist_MF = np.concatenate((doc_dist[boolean_mask_M],doc_dist[boolean_mask_F]))\n",
    "\n",
    "    joint_prob, marginal_by_topic, marginal_by_group, dist_diff_topic = project_lda_topics(race_dist_MF,doc_dist_MF)\n",
    "\n",
    "    return joint_prob, marginal_by_topic, marginal_by_group, dist_diff_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## race by paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imputing by the mean: 100%|██████████| 238652/238652 [00:01<00:00, 221769.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fc28bc03cf48e5b3631a04554e079e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='inferring race from lastnames'), FloatProgress(value=0.0, max=238652.0), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_socsci_race = infer_race(us_papers,df_socsci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lda_model,vectorizer = restore_model(df_socsci,dataset= 'socsci',n_components=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_components=300, n_jobs=-1,\n",
       "                          random_state=1234, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized_socsci_300, doc_dist_socsci_300 = transform_data(df_socsci_race,lda_model,vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_prob_gender, marginal_by_topic_gender, marginal_by_group_gender, dist_diff_topic_gender = intersect_by_gender(df_socsci_race, doc_dist_socsci_300,weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_prob_gender.to_csv('../results/joint_prob_gender_300_weighted.csv',index=False)\n",
    "marginal_by_topic_gender.to_csv('../results/marginal_by_topic_gender_300_weighted.csv',index=False)\n",
    "marginal_by_group_gender.to_csv('../results/marginal_by_group_gender_300_weighted.csv',index=False)\n",
    "dist_diff_topic_gender.to_csv('../results/dist_diff_topic_gender_300_weighted.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic proportion, weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dist_socsci_300_weighted = (doc_dist_socsci_300.T * df_socsci_race.cit_rel_all_IAC.values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_weighted = pd.DataFrame(doc_dist_socsci_300_weighted.sum(axis=0)/np.sum(doc_dist_socsci_300_weighted.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_weighted.columns = ['proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_weighted['topic'] = topic_proportion_weighted.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_weighted.to_csv('../results/topic_proportion_300_weighted.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health = pd.read_csv('/data/datasets/WOS/US/text_clean_health.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imputing by the mean: 100%|██████████| 123472/123472 [00:00<00:00, 204004.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a08d81d6c5451295331f2d2cd19b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='inferring race from lastnames'), FloatProgress(value=0.0, max=123472.0), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_health_race = infer_race(us_papers,df_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lda_model_health,vectorizer_health = restore_model(df_health,dataset= 'health',n_components=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized_health_200, doc_dist_health_200 = transform_data(df_health_race,lda_model_health,vectorizer_health)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_prob_gender_health, marginal_by_topic_gender_health, marginal_by_group_gender_health, dist_diff_topic_gender_health = intersect_by_gender(df_health_race, doc_dist_health_200,weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_prob_gender_health.to_csv('../results/joint_prob_gender_health_200_weighted.csv',index=False)\n",
    "marginal_by_topic_gender_health.to_csv('../results/marginal_by_topic_gender_health_200_weighted.csv',index=False)\n",
    "marginal_by_group_gender_health.to_csv('../results/marginal_by_group_gender_health_200_weighted.csv',index=False)\n",
    "dist_diff_topic_gender_health.to_csv('../results/dist_diff_topic_gender_health_200_weighted.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic proportion, weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dist_health_200_weighted = (doc_dist_health_200.T * df_health_race.cit_rel_all_IAC.values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_health_weighted = pd.DataFrame(doc_dist_health_200_weighted.sum(axis=0)/np.sum(doc_dist_health_200_weighted.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_health_weighted.columns = ['proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_health_weighted['topic'] = topic_proportion_health_weighted.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion_health_weighted.to_csv('../results/topic_proportion_health_200_weighted.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct projection of citations & race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_gender(df_race):\n",
    "    df_race['gender'] = df_race.gender.str.upper()\n",
    "    \n",
    "    boolean_mask_M = df_race.gender == 'M'\n",
    "    boolean_mask_F = df_race.gender == 'F'\n",
    "       \n",
    "    race_dist_M = df_race.loc[boolean_mask_M,['white','hispanic','black','asian']].copy()\n",
    "    race_dist_F = df_race.loc[boolean_mask_F,['white','hispanic','black','asian']].copy()\n",
    "\n",
    "    race_dist_M.columns = race_dist_M.columns + '_M'\n",
    "    race_dist_F.columns = race_dist_F.columns + '_F'\n",
    "\n",
    "    race_dist_MF = pd.concat([race_dist_M,race_dist_F]).fillna(0)\n",
    "    \n",
    "    assigned_gender_bool = np.asarray(boolean_mask_M) | np.asarray(boolean_mask_F)\n",
    "    cit_rel_all_IAC_MF = df_race.loc[assigned_gender_bool,'cit_rel_all_IAC']\n",
    "    return(race_dist_MF, cit_rel_all_IAC_MF, assigned_gender_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_citations_by_race(df_race):\n",
    "    \n",
    "    race_dist_MF, cit_rel_all_IAC_MF, _ = split_by_gender(df_race)\n",
    "    \n",
    "    n_citations = race_dist_MF.multiply(cit_rel_all_IAC_MF, axis=\"index\").sum(axis=0)\n",
    "    n_papers = race_dist_MF.sum(axis=0)\n",
    "\n",
    "    avg_citations_race = n_citations/n_papers\n",
    "    \n",
    "    return avg_citations_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_citations_by_topic(df_race,doc_dist, split=False):\n",
    "    \n",
    "    if split is True:\n",
    "        race_dist, cit_rel_all_IAC,assigned_gender_bool = split_by_gender(df_race)\n",
    "        doc_dist = doc_dist[assigned_gender_bool]\n",
    "    else:\n",
    "        race_dist = df_race.filter(regex=('white|hispanic|black|asian')).copy()\n",
    "        cit_rel_all_IAC = df_race[\"cit_rel_all_IAC\"]\n",
    "\n",
    "    citations_by_topics_and_group = race_dist.multiply(cit_rel_all_IAC, axis=\"index\").T @ doc_dist\n",
    "    papers_by_topics_and_group = race_dist.T @ doc_dist\n",
    "\n",
    "    avg_citation_by_topic_race = citations_by_topics_and_group/papers_by_topics_and_group    \n",
    "            \n",
    "    return avg_citation_by_topic_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_citations_race = average_citations_by_race(df_socsci_race)\n",
    "\n",
    "avg_citations_race.to_csv('../results/avg_citations_race_socsci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_citations_by_topic_gender_df = average_citations_by_topic(df_socsci_race,doc_dist_socsci_300,split=True)\n",
    "\n",
    "average_citations_by_topic_gender_df = average_citations_by_topic_gender_df.T\n",
    "average_citations_by_topic_gender_df['topic'] = average_citations_by_topic_gender_df.index + 1\n",
    "\n",
    "average_citations_by_topic_gender_df.to_csv('../results/average_citations_by_topic_gender_socsci.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_citations_by_topic_gender_df.loc[259]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_citations_race = average_citations_by_race(df_health_race)\n",
    "\n",
    "avg_citations_race.to_csv('../results/avg_citations_race_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_citations_by_topic_gender_df = average_citations_by_topic(df_health_race,doc_dist_health_200,split=True)\n",
    "\n",
    "average_citations_by_topic_gender_df = average_citations_by_topic_gender_df.T\n",
    "average_citations_by_topic_gender_df['topic'] = average_citations_by_topic_gender_df.index + 1\n",
    "\n",
    "average_citations_by_topic_gender_df.to_csv('../results/average_citations_by_topic_gender_health.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
